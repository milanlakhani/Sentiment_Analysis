{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggdGZDcSGZPb",
        "outputId": "a06c43d5-e6d5-46c1-f01f-af3054f42900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Sentiment/Inference\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cd /content/drive/MyDrive/Sentiment/Inference\n",
        "\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "import models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "4jpX5Vc7Gqo7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(model, file_name, device=None, optimizer=None):\n",
        "    if not device:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    ckpt = torch.load(file_name, map_location=device)\n",
        "    model_weights = ckpt['model_weights']\n",
        "    model.load_state_dict(model_weights)\n",
        "    print(\"Model's pretrained weights loaded!\")\n",
        "    if optimizer:\n",
        "        optimizer.load_state_dict(ckpt['optimizer_state'])\n",
        "    print(\"Optimizer's state loaded!\")"
      ],
      "metadata": {
        "id": "Osmt6cmrG9SJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./IMDB Dataset.csv\")\n",
        "\n",
        "# Convert to lower case\n",
        "df['review'] = df['review'].apply(lambda x:x.lower())\n",
        "\n",
        "# Remove punctuation\n",
        "df['clean_text'] = df['review'].apply(lambda x:''.join([c for c in x if c not in punctuation]))\n",
        "\n",
        "# Create list of reviews\n",
        "review_list = df['clean_text'].tolist()"
      ],
      "metadata": {
        "id": "D0bKOjpgo_TT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocab_int_dict(review_list):\n",
        "  # Create a list of words\n",
        "    review_list = ' '.join(review_list)\n",
        "    words = review_list.split()\n",
        "    # Count words using Counter Method\n",
        "    count_words = Counter(words)\n",
        "    vocab_to_int = {w:i+1 for i, (w,c) in enumerate(count_words.items())}\n",
        "    return vocab_to_int\n",
        "\n",
        "def pad_features(reviews_int, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.'''\n",
        "\n",
        "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
        "    for i, review in enumerate(reviews_int):\n",
        "        review_len = len(review)\n",
        "        if review_len <= seq_length:\n",
        "            zeroes = list(np.zeros(seq_length-review_len))\n",
        "            new = zeroes+review\n",
        "        elif review_len > seq_length:\n",
        "            new = review[0:seq_length]\n",
        "        features[i,:] = np.array(new)\n",
        "    return features\n",
        "\n",
        "def preprocess(review, vocab_to_int):\n",
        "    review = review.lower()\n",
        "    word_list = review.split()\n",
        "    num_list = []\n",
        "    reviews_int = []\n",
        "    for word in word_list:\n",
        "        if word in vocab_to_int.keys():\n",
        "            num_list.append(vocab_to_int[word])\n",
        "    reviews_int.append(num_list)\n",
        "    return reviews_int\n",
        "\n",
        "def predict(model, test_review, vocab_to_int, sequence_length=500):\n",
        "    ''' Prints out whether a given review is predicted to be positive or negative in sentiment.'''\n",
        "\n",
        "    int_rev = preprocess(test_review, vocab_to_int)\n",
        "    features = pad_features(int_rev, seq_length=seq_length)\n",
        "\n",
        "    features = torch.from_numpy(features)\n",
        "\n",
        "    model.eval()\n",
        "    val_h = model.init_hidden(1)\n",
        "    val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "    if(torch.cuda.is_available()):\n",
        "        features = features.cuda()\n",
        "        model = model.cuda()\n",
        "        val_h = tuple([each.cuda() for each in val_h])\n",
        "\n",
        "    output, val_h = model(features, val_h)\n",
        "\n",
        "    pred = torch.round(output)\n",
        "    output = [\"Positive\" if pred.item() == 1 else \"Negative\"]\n",
        "\n",
        "    print(output)\n"
      ],
      "metadata": {
        "id": "lyNt7UDCu6Go"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_to_int = get_vocab_int_dict(review_list)\n",
        "\n",
        "vocab_size = len(vocab_to_int) + 1\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "num_heads = 8\n",
        "drop_prob_1 = 0.5\n",
        "drop_prob_2 = 0.3\n",
        "\n",
        "model = models.SentimentAttentionLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, num_heads, drop_prob_1, drop_prob_2)\n",
        "\n",
        "load_checkpoint(model, \"LSTM-2_ckpt_epch_3.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz-JVKNd4vBe",
        "outputId": "a1f55c24-2b2c-45b4-d9c0-4879a017dd7f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's pretrained weights loaded!\n",
            "Optimizer's state loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test reviews\n",
        "test_review_pos = 'This movie had the best acting and the dialogue was so good. I loved it.'\n",
        "test_review_neg = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'\n",
        "\n",
        "# Call function\n",
        "seq_length=500\n",
        "print(test_review_pos)\n",
        "predict(model, test_review_pos, vocab_to_int, 500)\n",
        "print(test_review_neg)\n",
        "predict(model, test_review_neg, vocab_to_int, 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgjbtXgx43ZG",
        "outputId": "e883cc5b-b762-4b32-f279-65a02fd1af86"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This movie had the best acting and the dialogue was so good. I loved it.\n",
            "['Positive']\n",
            "The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.\n",
            "['Negative']\n"
          ]
        }
      ]
    }
  ]
}